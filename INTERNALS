
  ~ the nature of potion's insides ~

  Potion's internals are based around the idea
  that things that happen frequently should be
  given the greater attention.

  For example, code execution happens more often
  than code parsing and loading. Therefore, the
  VM is larger and faster than the parser and
  compiler.

  Other things that happen frequently:

   * Math.
   * Conditionals.
   * Method dispatch.
   * Local variables.
   * Strings, to build and compare.
   * Memory allocation.

  More sporadic things likely include:

   * New methods.
   * Creation of classes.
   * Very deep scoping situations.
   * Altering the inheritance tree.
   * Evals.
   * Code allocation.

  So understand that often the choices made in
  Potion's VM are designed to accomodate the
  first set rather than the second.

                     ~

  This doc is going to touch quite a bit on
  the JIT, compiling straight to x86 and PowerPC
  instructions. So many languages are targetting
  the JVM and .Net these days... it made me
  wonder what the hurdles are to generating
  machine code directly.

  Clearly, the biggest benefit of having a
  common runtime is garbage collection. The
  JVM has some wild GC algorithms built in.
  And that's actually a huge benefit. I only
  wish that more garbage collectors were
  available as libraries.

  Anyways, my favorite language has been Ruby
  for many years, that's partially because
  I like how easy it is to script from C,
  for some efficiency where I need it. So
  Potion is my little attempt to make a
  language that feels easy, but compiles
  to machine code, to give me the speed of
  (un-optimized) C code and to use all the
  C function call conventions so that I
  can link to other C libs. I want to see
  if its still possible to enroach on C.

  I should say that O'Caml and Haskell
  already do a fine job as C competitors,
  so it's not like anything here is that
  new.


  ~ lua's influence ~

  Potion used a register-based bytecode VM that
  is nearly a word-for-word copy of Lua's. The
  code is all different, but the bytecode is
  nearly identical.

  I also spelunked Neko VM for some ideas and
  found this comparison very useful.
  <http://nekovm.org/lua>

  I also took from the Lua the notion of using
  tables for everything. And, like Lua, lists
  and tables are interchangeable. But, in Potion,
  I kept their representations separate.

  I also use immutable strings, like Lua.

  However, my object representation is more
  like Neko or Ruby, where objects are all
  represented by 32-bit values.


  ~ the parts of potion ~

  1. the parser
     - lexer written with Ragel
       (see core/pn-scan.rl)
     - parser written with Lemon
       (see core/pn-scan.y)
     - produces a syntax tree
     - the tree is a Potion object that can
       be traversed in the code
     - see potion_source_load()
       in core/compile.c

  2. the compiler
     - compiles a syntax tree into
       bytecode (see core/compile.c)
     - has its own file format
       (save to .pnb files)
     - interception of keywords
       happens here, rather than in
       the parser, to simplify parsing

  3. the vm
     - executes bytecode
     - used mostly to ensure correctness
     - helpful in debugging
     - run code on non-x86 with performance
       penalty

  4. the jit
     - compiles bytecode into a function
       pointer
     - uses the same argument passing strategy
       as c functions


  ~ the jit ~

  The X86 JIT is the first half of core/vm.c.
  The code translates Potion bytecode into
  32-bit or 64-bit machine code.

  In the code:

    add = (x, y): x + y.

  The `add` closure is compiled into a c function
  pointer looking like this:

    PN (*)(Potion *P, PN cl, PN self, PN x, PN y)

  This means you can actually load this closure
  into C and call it directly.

    Potion *P = potion_create();
    PN add = potion_eval(P, "(x, y): x + y.");
    PN_F addfn = PN_CLOSURE_F(add);
    PN num = addfn(P, 0, 0, PN_NUM(3), PN_NUM(5));
    printf("3 + 5 = %d\n", PN_INT(num));

  The macros are there to allow bytecode to be
  wrapped in a function pointer, if needed. The
  inside story looks like this:

    PN num = ((struct PNClosure *)add)->method(
               P, 0, 0, PN_NUM(3), PN_NUM(5));


  ~ the jit's assembly ~

  Now, let's talk about the compiled code.

  Earlier the example was,

    add = (x, y): x + y.

  So we have a function with two arguments
  and a math operation.

  The C equivalent is,

    PN add(Potion *P, PN cl, PN self, PN x, PN y) {
      PN reg1 = x;
      PN reg2 = y;
      reg1 = PN_NUM(PN_INT(reg1) + PN_INT(reg2));
      return reg1;
    }

  The arguments are moved to registers on the
  stack. Then converted to ints. Then added.
  And, lastly, the result is cast as a Potion
  object.

  The machine code produced by the JIT will
  be very close to the code produced by a
  compiler with the optimizations turned off.
  (At least for the present this is true.)

  Like C functions, Potion keeps local variables
  on the stack. The call stack is like a big tape
  measure that goes on and on. Since this function
  has two registers (reg1 and reg2,) we need
  two inches from the tape measure.

  <http://en.wikipedia.org/wiki/Call_stack>
  (See the parts that say "Local data storage"
  and "Argument passing".)

  Our machine code says "give me two word-sized
  slots in the stack" as the first order of business.

  We store `x` and `y` in those two slots. (See
  the comment about C argument passing in the
  next section.)

  Then we do the math. Even the PN_INT and
  PN_NUM macros are fundamentally math.

  If you run Potion with -V on this script,
  you'll see a bytecode disassembly.

    ; function ; 16 bytes
    ; (x, y) 2 registers
    .local "x" ; 0
    .local "y" ; 1
    [1] getlocal 0 0
    [2] getlocal 1 1
    [3] add 0 1
    [4] return 0

  Each of these lines corresponds to a line of
  C code inside that function a few paragraphs
  back. You see how they line up there?


  ~ x86 and x86-64 ~

  64-bit CPU instructions are a superset of
  32-bit CPU instructions. And many 32-bit
  instructions can be converted to 64-bit by
  prefixing them.

  Take this code,

    8b 55 f8  // mov %ebp[-1] %edx
    8b 45 fc  // mov %ebp[-2] %eax
    83 e8 04  // sub 0x4 %edx
    89 50 04  // mov %edx %eax[1]

  These are the 32-bit instructions for altering
  an upval. (A variable in another scope.) Since
  a closure doesn't have access to the registers
  of another function, these variables are passed
  as pointers (the PNWeakRef struct.)

  This code loads the upval into %eax and the new
  value into %edx. To get the upval's actual struct
  pointer, we subtract 4 from %edx. Finally, we
  move the new value into offset 4 in the struct
  pointed to by the upval.

  In 64-bit code this would be,

    48 8b 55 f0  // mov %rbp[-1] %rdx
    48 8b 45 f8  // mov %rbp[-2] %rax
    83 e8 04     // sub 0x4 %edx
    48 89 50 08  // mov %rdx %rax[1]

  All it took was adding the 0x48 prefix to our
  mov instructions and changing our offsets to
  measure 8 bytes rather than 4. The third
  instruction actually stays the same, since
  we're only doing math on the lower 32-bits of
  the upval.

  We now call the registers %rax and %rdx.
  That's just what the CPU folks call em.

  The only other technique that changes between
  32-bit and 64-bit is function calling. On 32-
  bit, we keep all the function arguments on
  the stack. On 64-bit, some function arguments
  are passed through registers.

  That's the purpose behind the function named
  potion_x86_c_arg. To shuttle the arguments
  in and out, depending on the architecture.

  ~ using disassemblers ~

  I don't really know the x86 instruction set
  too well and most often I just write something
  in C and disassemble it.

    $ gcc test.c -o test
    $ objdump --disassemble-all test

  However, objdump doesn't come with the OS X
  dev tools, so you can use the included
  machodis.pl by Robert Kelp to inspect the
  binary.

    $ ./tools/machodis.pl test

